[{"categories":["Computer Network"],"content":"可靠数据传输原理  可靠数据传输(Reliable Data Transfer)是一个很大的概念，在计算机网络的五层模型中，它可以出现在传输层、数据链路层和应用层。简单点说，可靠数据传输服务保证了通信过程中的数据接收方接收到的数据与其从数据发送方发出的数据一致。而提供这种可靠数据传输服务的协议称为可靠数据传输协议，例如传输层的TCP协议。  可靠数据传输为上层实体提供的服务抽象是：数据可以通过一条可靠的信道进行传输。在这条信道中传输的数据bit不会受到损坏和或丢失，而且所有的数据都是按其发送顺序交付。其对应的服务框架如下图所示，TCP协议向调用它的因特网应用所提供的服务模型恰恰如此，所以当谈到可靠数据传输时，不可避免地会涉及大量TCP协议的分析。  那么一个网络协议要实现可靠数据传输需要具备哪些特性呢？或者说，协议中需要设定哪些规则来避免数据传输的不可靠？为了数据传输的可靠，我们就要解决数据不可靠的情况，而数据传输的不可靠的情形最基本的有如下几种： 数据在信道中传输时，比特出现了错误，例如本来该bit为0，到了接收端却成为了1 数据在信道中传输时，比特发生了丢失，例如本来按序发送了16个比特，结果到了接收端只收到了8个比特 数据在信道中传输时，比特流的顺序发生了变化，例如发送端按照序号1，2，3，4，5发送的比特流，结果到了接收端收到是1，3，2，5，4 数据在信道中传输时，接收端接收到了重复的数据，例如发送端按照序号1，2，3发送，到了接收端收到是1，2，2，3  先思考一下，针对上面的若干基本情况，我们要怎么处理。首先数据在接收方出现了不一致的情况，我们如何得知呢？这就需要通过差错检测机制，通过差错检测，我们可以检测到何时何处出现了比特差错。然后，出现了差错该怎么办呢？作为接收方，肯定要告诉发送方我收到的数据有问题，所以就要有接收方反馈功能，也就是接收方发送明确的反馈信息给发送方。那么发送方接收了该反馈信息又该怎么做呢？最基本且有效的情况无非就是重新发送一份错误数据对应的原数据，也就是重传。 差错检测 ​ 差错检测主要的实现方式就是在传输的数据流中添加额外的比特信息以增加冗余度，主要分为两大类：奇偶效验和分组检验。其中分组校验中典型的方法有校验和法（IP数据报）和循环冗余校验法。 接收方反馈 一般是给出肯定确认ACK或否定确认NAK，也可以通过冗余ACK的方式代替否定确认。 重传 在分组传送时，主要有累积重传和选择重传。  通过上述几个功能，我们可以设计出能够工作的协议，但是，仔细想象一下你就会发现，这个步骤中有一个致命缺陷。在接收方给发送方发送反馈信息时，假设这个反馈信息也出了错误，那么发送方就无法知道接收方是否正确接收上一次发送的数据了。 在思考一下，如果我们是协议设计者，会怎么做？可以考虑以下几种方式： 发送方接收到错误的反馈信息表示无法理解时，便又向接收方发送针对该反馈信息的解释请求，即引入了一种新型的从发送方到接收方的分组。就像打电话时一方不理解另一方时会提问“你说啥？”，另一方则会重复回答。要是这个“你说啥”也产生了差错，岂不又是越陷越深了。 增加足够的检验和比特，使得发送方不但可以检测差错还可以恢复差错，对于只产生错误而没有丢失的分组，就可以直接解决问题。 当发送方收到含糊不清的反馈信息后，只需要重传当前数据分组即可。这种方法在信道中引入了冗余分组。而冗余分组所带来一个问题就是，接收方不知道它上次发送的反馈信息是否被发送方正确接收，也就是说接收方无法事先知道接收到的分组时新的还是一次重传，这很重要，因为如果将重传分组当作新的分组，那么数据包就会出错了。 序号 ​ 为了解决上述冗余分组中的问题，我们就又提出一种协议功能，就是给数据分组编号，这也是包括TCP在内所有的数据分组采用的方法。即在数据分组中添加一个新的字段，让发送方对其数据分组编号，将发送数据分组的序号放在该字段。于是，接收方只需要检查序号就可以确定该分组是否是一次重传了。对于停等协议（Stop and Wait，SW）来说，该字段只需要一个比特即可。因为停等协议中，发送方必须等待接收方传回ACK或NAK才能继续发送下一个数据分组。  除了具备差错检测与恢复外，我们还需要考虑当分组丢失分情况，而上面的协议功能不足以解决分组丢失的问题。当发送方发送一个数据后，在信道中丢失，接收方自然没有收到数据从而不会发送反馈，于是发送方迟迟没有收到确认。这时候，我们一般情况下都是会等待一定时间后重新发送该分组。所以我们又引入一个新的协议功能：倒计数定时器，通过设定一个给定的时间量，当时间量过期后，便重传分组。 倒计数定时器 为了容忍数据丢失，我们在发送方引入倒计数定时器。即1. 每次发送一个分组时（包括第一次分组和重传分组），启动一个定时器。2. 响应定时器中断（采取适当动作，比如重传）。3. 终止定时器。  综上，在实现了差错检测，接收方反馈，重传，序号，倒计数定时器这些协议功能后，就可以得到一个可靠数据传输协议了。 具备上述协议功能的协议分为两种，一种是停止-等待协议，一种是流水线协议，后者是前者的加强版，提升了信道的利用率。实际上ARQ协议也是分为了类似的两类。说到ARQ，那么就介绍一下它：  ARQ协议，即自动重传请求（Automatic Repeat-reQuest），是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议，拥有错误检测（Error Detection）、正面确认（Positive Acknowledgment）、超时重传（Retransmission after Timeout）和 负面确认及重传（Negative Acknowledgment and Retransmission）等机制。其中，连续ARQ就是一种流水线协议。  我们说到流水线协议相对于停止等待协议增加了信道的利用率，但是也带来了一定程度的局限性。例如： 流水线协议必须增加序号的范围，因为每个传输中的分组必须有一个唯一的序号用来区分分组，而且也许在输送中存在多个未确认的报文。而停止等待协议只需一个比特位来给分组编号（即比特交替协议） 协议的发送方和接收方两端也许必须缓存多个分组。这样做的目的是为了差错恢复，这取决于协议如何处理丢失、损坏以及时延过大的分组所需序号范围i和对缓冲的要求取决于数据传输协议如何 流水线协议中差错恢复的两种方法：回退N步（Go-Back-N,GBN）和选择重传（Selective Repeat,SR）。 回退N步协议(GBN)  回退N步协议允许发送方发送多个分组而不确认，但是其在流水线中未确认的分组的数量不能超过N。这个协议又被称作滑动窗口协议，是因为流水线中已被发送但还未被确认的分组的许可范围构成了一个在序号范围内长度为N的窗口，N就是窗口的大小，随着协议运行，该窗口的序号空间不断向前滑动。思考一下，为什么要设置这么一个窗口呢？其实是为了流量控制和拥塞控制的需要，我们将在后文介绍。 在GBN中，发送方必须响应的三种类型事件是： 上层的调用。 收到一个ACK，该协议对序号为n的分组的确认采取累积确认的方式，表明接收方已经正确接收到序号为n的以前且包括n在内的所有分组。 超时事件，go-back N行为正来自出现丢失或时延过长分组时发送方采取的差错恢复行为。同样也用到了定时器，出现超时的时候，发送方将重传所有已发送但还未被确认的分组，所以在发送方缓存这些分组是十分必要的。如果收到一个ACk,但仍有已发送但未确认的分组，则定时器会被重新启动，如果没有则会终止。 GBN协议中，接收方会丢弃失序的分组，因为GBN采用累积确认，一次交付给上层一个分组，接收方必须按序将数据交付给上层，丢失分组是一种简单的方法之一，另外的一种就是放在接收方缓存起来，等带下一个按序的分组，最后在组装正确的数据交付。 选择重传协议(SR) GBN虽然采用了流水线解决了信道利用率的问题，但是也会存在另外的性能问题，例如当窗口长度很大或者带宽时延积都很大时，在流水线中有更多的分组时更甚。因为在这些情况下，必须重传大量分组，代价太大了，也许只是窗口中诸多分组的一个或几个分组出现错误，便要重传全部已经发送但未确认的分组，未免太浪费了。 而选择重传机制就是让发送方仅仅重传那些它怀疑在接收方出错(丢失或受损)的分组，从而避免了不必要的重传。但是这种方式就不能采用累积确认了，而是要求接收方逐个地确认正确接收的分组。即接收方确认正确的分组不管其是否失序，失序的分组将被缓存直到所有比失序分组序号小的分组都被接收为止，才会将一批分组按序交付。 但是这种方式会带来一个问题，就是接收方和发送方的窗口并不是总是一致的，因为对于哪些分组已经被正确接收，哪些没有，发送方和接收方并不是总能看到一样的结果。这意味着，当序号范围有限时，发送方和接收窗口之间缺乏同步会产生严重的后果。这就要求SR协议中，窗口长度必须小于或等于序号空间大小的一半。后续将证明。 到现在为止，我们介绍了若干可靠传输机制，下表是一个总结。 机制 用途和说明 检验和 用于检测在一个传输分组中的比特错误 定时器 用于超时/重传一个分组,可能因为该分组(或其ACK)在信道中丢失了。由于当一个分组延时但未丢失，或当一个分组已被接收方接收但从接收方到发送方的ACK丢失时，可能产生超时事件，所以接收方可能会收到一个分组的多个冗余副本 序号 用于为从发送方流向接收方的数据分组按序号编号。所接受分组的序号的","date":"2022-01-07","objectID":"/reliable_data_transfer/:0:1","tags":["Reliable Data Transfer","TCP","Computer Network"],"title":"计算机网络是如何实现可靠数据传输的？","uri":"/reliable_data_transfer/"},{"categories":["Computer Network"],"content":"从TCP协议中看可靠数据传输 未完待续 流量控制 拥塞控制 ","date":"2022-01-07","objectID":"/reliable_data_transfer/:0:2","tags":["Reliable Data Transfer","TCP","Computer Network"],"title":"计算机网络是如何实现可靠数据传输的？","uri":"/reliable_data_transfer/"},{"categories":["随笔"],"content":"滕王阁序 王勃 【唐代】 　豫章故郡，洪都新府。星分翼轸，地接衡庐。襟三江而带五湖，控蛮荆而引瓯越。物华天宝，龙光射牛斗之墟；人杰地灵，徐孺下陈蕃之榻。雄州雾列，俊采星驰。台隍枕夷夏之交，宾主尽东南之美。都督阎公之雅望，棨戟遥临；宇文新州之懿范，襜帷暂驻。十旬休假，胜友如云；千里逢迎，高朋满座。腾蛟起凤，孟学士之词宗；紫电青霜，王将军之武库。家君作宰，路出名区；童子何知，躬逢胜饯。 　时维九月，序属三秋。潦水尽而寒潭清，烟光凝而暮山紫。俨骖騑于上路，访风景于崇阿。临帝子之长洲，得天人之旧馆。层峦耸翠，上出重霄；飞阁流丹，下临无地。鹤汀凫渚，穷岛屿之萦回；桂殿兰宫，即冈峦之体势。 　披绣闼，俯雕甍，山原旷其盈视，川泽纡其骇瞩。闾阎扑地，钟鸣鼎食之家；舸舰弥津，青雀黄龙之舳。云销雨霁，彩彻区明。落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨，雁阵惊寒，声断衡阳之浦。 　遥襟甫畅，逸兴遄飞。爽籁发而清风生，纤歌凝而白云遏。睢园绿竹，气凌彭泽之樽；邺水朱华，光照临川之笔。四美具，二难并。穷睇眄于中天，极娱游于暇日。天高地迥，觉宇宙之无穷；兴尽悲来，识盈虚之有数。望长安于日下，目吴会于云间。地势极而南溟深，天柱高而北辰远。关山难越，谁悲失路之人；萍水相逢，尽是他乡之客。怀帝阍而不见，奉宣室以何年？ 　嗟乎！时运不齐，命途多舛。冯唐易老，李广难封。屈贾谊于长沙，非无圣主；窜梁鸿于海曲，岂乏明时？所赖君子见机，达人知命。老当益壮，宁移白首之心？穷且益坚，不坠青云之志。酌贪泉而觉爽，处涸辙以犹欢。北海虽赊，扶摇可接；东隅已逝，桑榆非晚。孟尝高洁，空余报国之情；阮籍猖狂，岂效穷途之哭！ 　勃，三尺微命，一介书生。无路请缨，等终军之弱冠；有怀投笔，慕宗悫之长风。舍簪笏于百龄，奉晨昏于万里。非谢家之宝树，接孟氏之芳邻。他日趋庭，叨陪鲤对；今兹捧袂，喜托龙门。杨意不逢，抚凌云而自惜；钟期既遇，奏流水以何惭？ 　呜呼！胜地不常，盛筵难再；兰亭已矣，梓泽丘墟。临别赠言，幸承恩于伟饯；登高作赋，是所望于群公。敢竭鄙怀，恭疏短引；一言均赋，四韵俱成。请洒潘江，各倾陆海云尔。 滕王高阁临江渚，佩玉鸣鸾罢歌舞。 画栋朝飞南浦云，珠帘暮卷西山雨。 闲云潭影日悠悠，物换星移几度秋。 阁中帝子今何在？槛外长江空自流。 ","date":"2021-11-04","objectID":"/first/:0:0","tags":null,"title":"滕王阁序","uri":"/first/"},{"categories":["C/C++"],"content":"GCC 编译工具 GCC是一款强大的编译工具，下文在介绍c以及c++程序的编译运行流程中将采用gcc做示例。 GCC的初衷是为GNU操作系统专门编写的一款编译器。GNU系统是彻底的自由软件。此处，“自由”的含义是它尊重用户的自由 [2] 。 GCC 原名为 GNU C语言编译器（GNU C Compiler） GCC（GNU Compiler Collection，GNU编译器套件）是由 GNU 开发的编程语言编 译器。GNU 编译器套件包括 C、C++、Objective-C、Java、Ada 和 Go 语言前端，也包括了这些语言的库（如 libstdc++，libgcj等） GCC 不仅支持 C 的许多“方言”，也可以区别不同的 C 语言标准；可以使用命令行选项来控制编译器在翻译源代码时应该遵循哪个 C 标准。例如，当使用命令行参数 -std=c99 启动 GCC 时，编译器支持 C99 标准。 安装命令 sudo apt install gcc g++ （版本 \u003e 4.8.5） 查看版本 gcc/g++ -v/--version ","date":"2021-05-19","objectID":"/compile_link/:1:0","tags":["C/C++","GNU","Compile"],"title":"编译与链接","uri":"/compile_link/"},{"categories":["C/C++"],"content":"1.gcc 和 g++ 的关系 gcc 和 g++都是GNU(组织)的一个编译器。 后缀为 .c 的，gcc 把它当作是 C 程序，而 g++ 当作是 c++ 程序 后缀为 .cpp 的，两者都会认为是 C++ 程序，C++ 的语法规则更加严谨一些 编译阶段，g++ 会调用 gcc，对于 C++ 代码，两者是等价的，但是因为 gcc 命令不能自动和 C++ 程序使用的库联接，所以通常用 g++ 来完成链接，为了统 一起见，干脆编译/链接统统用 g++ 了，这就给人一种错觉，好像 cpp 程序只能用 g++ 似的 宏__cplusplus只是标志着编译器将会把代码按 C 还是 C++ 语法来解释，如果后缀为 .c，并且采用 gcc 编译器，则该宏就是未定义的，否则，就是已定义 编译可以用 gcc/g++，而链接可以用 g++ 或者 gcc -lstdc++ gcc 命令不能自动和C++程序使用的库联接，所以通常使用 g++ 来完成联接。 但在编译阶段，g++ 会自动调用 gcc，二者等价 ","date":"2021-05-19","objectID":"/compile_link/:1:1","tags":["C/C++","GNU","Compile"],"title":"编译与链接","uri":"/compile_link/"},{"categories":["C/C++"],"content":"2.gcc 常用编译参数 -E 预处理指定的源文件，不进行编译 -S 编译指定的源文件，但是不进行汇编 -c 编译、汇编指定的源文件，但是不进行链接 -o [file1] [file2] /[file2] -o [file1] 将文件 file2 编译成可执行文件 file1 -I directory 指定 include 包含文件的搜索目录 -g 在编译的时候，生成调试信息，该程序可以被调试器调试 -D 在程序编译的时候，指定一个宏 -w 不生成任何警告信息 -Wall 生成所有警告信息 -On n的取值范围：0~3。编译器的优化选项的4个级别，-O0表示没有优化，-O1为缺省值，-O3优化级别最高 -l 在程序编译的时候，指定使用的库 -L 指定编译的时候，搜索的库的路径。 -fPIC/fpic 生成与位置无关的代码 -shared 生成共享目标文件，通常用在建立共享库时 -std 指定C方言，如:-std=c99，gcc默认的方言是GNU C ","date":"2021-05-19","objectID":"/compile_link/:1:2","tags":["C/C++","GNU","Compile"],"title":"编译与链接","uri":"/compile_link/"},{"categories":["C/C++"],"content":"3.GCC 工作流程 GCC工作流程也就是一个c/c++语言程序从编译到生成可执行程序的过程，如下图所示。 下面分别介绍各个阶段,我们的示例代码如下： . ├── include │ ├── mymath.c │ └── mymath.h └── test.c test.c #include \u003cstdio.h\u003e#include \"mymath.h\" int main(int argc, char **argv) { int a = 2, b = 3; int sum = add(a, b); printf(\"a=%d, b=%d, a+b=%d\", a, b, sum); return 0; } mymath.h #ifndef MYMATH_H #define MYMATH_H int add(int a, int b); int sub(int a, int b); int mul(int a, int b); double div(int a, int b); #endif mymath.c int add(int a, int b) { return a + b; } int sub(int a, int b) { return a - b; } int mul(int a, int b) { return a * b; } double div(int a, int b) { return a * 1.0 / b; } ","date":"2021-05-19","objectID":"/compile_link/:1:3","tags":["C/C++","GNU","Compile"],"title":"编译与链接","uri":"/compile_link/"},{"categories":["C/C++"],"content":"1.预处理（Preprocessing） 预处理用于将所有的#include头文件以及宏定义替换成其真正的内容，预处理之后得到的仍然是文本文件，但文件体积会大很多。 预处理器的主要作用就是: 把通过预处理的内建功能对一个资源进行等价替换，最常见的预处理有: 文件包含，条件编译、布局控制和宏替换4种。 文件包含: #include 是一种最为常见的预处理，主要是做为文件的引用组合源程序正文。 条件编译: #if,#ifndef,#ifdef,#endif,#undef等也是比较常见的预处理，主要是进行编译时进行有选择的挑选，注释掉一些指定的代码，以达到版本控制、防止对文件重复包含的功能。 布局控制: #progma，这也是我们应用预处理的一个重要方面，主要功能是为编译程序提供非常规的控制流信息。 宏替换: #define，这是最常见的用法，它可以定义符号常量、函数功能、重新命名、字符串的拼接等各种功能。 gcc的预处理是预处理器cpp来完成的，你可以通过如下命令对test.c进行预处理 : # -I 指定头文件目录 # -E 指定编译器在预处理后就退出，不再进行后续编译过程 # -o 指定输出的文件名 gcc -E test.c -I ./include -o test.i # 或者直接用cpp命令 cpp test.c -I ./include -o test.i 执行结果为： -rw-r--r-- 1 lwy lwy 106 Apr 6 20:56 test.c -rw-r--r-- 1 lwy lwy 16349 Apr 6 21:14 test.i 看得出来经过预处理后的文件比源文件要大很多，预处理之后的程序还是文本，可以用文本编辑器打开。其内容大致如下： # 1 \"test.c\" # 1 \"\u003cbuilt-in\u003e\" # 1 \"\u003ccommand-line\u003e\" # 31 \"\u003ccommand-line\u003e\" # 1 \"/usr/include/stdc-predef.h\" 1 3 4# 32 \"\u003ccommand-line\u003e\" 2 # 1 \"test.c\" # 1 \"/usr/include/stdio.h\" 1 3 4# 27 \"/usr/include/stdio.h\" 3 4 ... typedef unsigned char __u_char; typedef unsigned short int __u_short; typedef unsigned int __u_int; typedef unsigned long int __u_long; ... # 4 \"test.c\" int main(int argc, char **argv) { printf(\"hello world\"); return 0; } ","date":"2021-05-19","objectID":"/compile_link/:2:0","tags":["C/C++","GNU","Compile"],"title":"编译与链接","uri":"/compile_link/"},{"categories":["C/C++"],"content":"2.编译（Compilation） 这里的编译不是指程序从源文件到二进制程序的全部过程，而是指将经过预处理之后的程序转换成特定汇编代码(assembly code)的过程。编译的指令如下： gcc -S -I ./include test.c -o test.s 上述命令中-S让编译器在编译之后停止，不进行后续过程。编译过程完成后，将生成程序的汇编代码test.s，内容如下： .file \"test.c\" .text .section .rodata .LC0: .string \"hello world\" .text .globl main .type main, @function main: .LFB0: .cfi_startproc endbr64 pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 subq $16, %rsp movl %edi, -4(%rbp) movq %rsi, -16(%rbp) leaq .LC0(%rip), %rdi movl $0, %eax call printf@PLT movl $0, %eax leave .cfi_def_cfa 7, 8 ret .cfi_endproc .LFE0: .size main, .-main .ident \"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04) 9.4.0\" .section .note.GNU-stack,\"\",@progbits .section .note.gnu.property,\"a\" .align 8 .long 1f - 0f .long 4f - 1f .long 5 0: .string \"GNU\" 1: .align 8 .long 0xc0000002 .long 3f - 2f 2: .long 0x3 3: .align 8 4: ","date":"2021-05-19","objectID":"/compile_link/:3:0","tags":["C/C++","GNU","Compile"],"title":"编译与链接","uri":"/compile_link/"},{"categories":["C/C++"],"content":"3.汇编（Assemble） 汇编过程将上一步的汇编代码转换成机器码(machine code)，这一步产生的文件叫做目标文件，是二进制格式。gcc汇编过程通过gcc -c命令完成： gcc -c test.s -o test.o gcc -c ./include/mymath.c -o ./include/mymath.o 这一步会为每一个源文件产生一个目标文件。因此mymath.c也需要产生一个mymath.o文件 . ├── include │ ├── mymath.c │ ├── mymath.h │ └── mymath.o ├── test.c ├── test.i ├── test.o └── test.s ","date":"2021-05-19","objectID":"/compile_link/:4:0","tags":["C/C++","GNU","Compile"],"title":"编译与链接","uri":"/compile_link/"},{"categories":["C/C++"],"content":"4.链接（Linking） 链接过程将多个目标文件以及所需的库文件(.so等)链接成最终的可执行文件(executable file),其命令如下 gcc -o test.out test.o include/mymath.o # 这里用g++也可，当是c++程序时倾向使用g++ . ├── include │ ├── mymath.c │ ├── mymath.h │ └── mymath.o ├── test.c ├── test.i ├── test.o ├── test.out └── test.s ./test.out 结果为： lwy@lwysLaptop:~/workspace/test$ ./test.out hello world 经过以上分析，我们发现编译过程并不像想象的那么简单，而是要经过预处理、编译、汇编、链接。尽管我们平时使用gcc命令的时候没有关心中间结果，但每次程序的编译都少不了这几个步骤。也不用为上述繁琐过程而烦恼，因为你仍然可以： gcc/g++ -c test.c -o test.out ","date":"2021-05-19","objectID":"/compile_link/:5:0","tags":["C/C++","GNU","Compile"],"title":"编译与链接","uri":"/compile_link/"},{"categories":["Tools"],"content":" GDB 是由 GNU 软件系统社区提供的调试工具，同 GCC 配套组成了一套完整的开发环境，GDB 是 Linux 和许多类 Unix 系统中的标准开发环境 GDB调试的三种方式： 目标板直接使用GDB进行调试。 目标板使用gdbserver，主机使用xxx-linux-gdb作为客户端。 目标板使用ulimit -c unlimited，生成core文件；然后主机使用xxx-linux-gdb ./test ./core。 ","date":"2021-04-07","objectID":"/gdb/:0:0","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"GDB 调试 构造测试程序如下main.c和sum.c如下: // main.c: #include \u003cstdio.h\u003e#include \u003cstdlib.h\u003e extern int sum(int value); struct inout { int value; int result; }; int main(int argc, char * argv[]) { struct inout * io = (struct inout * ) malloc(sizeof(struct inout)); if (NULL == io) { printf(\"Malloc failed.\\n\"); return -1; } if (argc != 2) { printf(\"Wrong para!\\n\"); return -1; } io -\u003e value = *argv[1] - '0'; io -\u003e result = sum(io -\u003e value); printf(\"Your enter: %d, result:%d\\n\", io -\u003e value, io -\u003e result); return 0; } // sum.c: int sum(int value) { int result = 0; int i = 0; for (i = 0; i \u003c value; i++) result += (i + 1); return result; } 然后gcc main.c sum.c -o main -g, 得到main可执行文件， 输入gdb main可进入调试. 下面介绍了gdb大部分功能，1.1 设置断点以及 1.3显示栈帧是常用功能；调试过程中可以需要1.6 单步执行，并且1.4 显示变量、1.5显示寄存器、1.8 监视点、1.9 改变变量的值。 如果进程已经运行中，需要1.11 attach到进程，或者1.10 生成转储文件进行分析。当然为了提高效率可以自定义1.13 初始化文件。 ","date":"2021-04-07","objectID":"/gdb/:1:0","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"设置断点* 设置断点可以通过b或者break设置断点，断点的设置可以通过函数名、行号、文件名+函数名、文件名+行号以及偏移量、地址等进行设置。 格式为： break 函数名 break 行号 break 文件名:函数名 break 文件名:行号 break +偏移量 break -偏移量 break *地址 查看断点，通过info break查看断点列表。 (gdb) b 13 Breakpoint 1 at 0x11aa: file main.c, line 13. (gdb) b sum.c:2 Breakpoint 2 at 0x123d: file sum.c, line 2. (gdb) info b Num Type Disp Enb Address What 1 breakpoint keep y 0x00000000000011aa in main at main.c:13 2 breakpoint keep y 0x000000000000123d in sum at sum.c:2 删除断点通过命令包括： delete \u003c断点id\u003e：删除指定断点 delete：删除所有断点 clear clear 函数名 clear 行号 clear 文件名：行号 clear 文件名：函数名 断点还可以条件断住 break 断点 if 条件；比如break sum if value==9，当输入的value为9的时候才会断住。 condition 断点编号：给指定断点删除触发条件 condition 断点编号 条件：给指定断点添加触发条件 断点还可以通过disable/enable临时停用启用。 disable disable 断点编号 disable display 显示编号 disable mem 内存区域 enable enable 断点编号 enable once 断点编号：该断点只启用一次，程序运行到该断点并暂停后，该断点即被禁用。 enable delete 断点编号 enable display 显示编号 enable mem 内存区域 断点commands高级功能 大多数时候需要在断点处执行一系列动作，gdb提供了在断点处执行命令的高级功能commands。 #include \u003cstdio.h\u003e int total = 0; int square(int i) { int result=0; result = i*i; return result; } int main(int argc, char **argv) { int i; for(i=0; i\u003c10; i++) { total += square(i); } return 0; } 比如需要对如上程序square参数i为5的时候断点，并在此时打印栈、局部变量以及total的值 编写gdb.init如下： set logging on gdb.log b square if i == 5 commands bt full i locals p total print \"Hit break when i == 5\" end 在gdb shell中source gdb.init，然后r执行命令，结果如下： (gdb) source gdb.init Breakpoint 1 at 0x1129: file commands.c, line 6. (gdb) r Starting program: /home/lwy/workspace/gdbtest/commands Breakpoint 1, square (i=5) at commands.c:6 6 { #0 square (i=5) at commands.c:6 result = 25 #1 0x000055555555516f in main (argc=1, argv=0x7fffffffe048) at commands.c:20 i = 6 result = 25 $1 = 55 $2 = \"Hit break when i == 5\" 可以看出断点在i==5的时候断住了，并且此时打印了正确的值。 ","date":"2021-04-07","objectID":"/gdb/:1:1","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"运行 “gdb 命令”之后，run可以在gdb下运行命令；如果命令需要参数则跟在run之后。 (gdb) run 9 Starting program: /home/lwy/workspace/gdbtest/main 9 Your enter: 9, result:45 [Inferior 1 (process 12362) exited normally] 如果需要断点在main()处，直接执行start就可以。 (gdb) start Temporary breakpoint 1 at 0x555555555189: file main.c, line 11. Starting program: /home/lwy/workspace/gdbtest/main 9 Temporary breakpoint 1, main (argc=21845, argv=0x0) at main.c:11 ","date":"2021-04-07","objectID":"/gdb/:1:2","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"显示栈帧* 如果遇到断点而暂停执行，或者coredump可以显示栈帧。 通过bt可以显示栈帧，bt full可以显示局部变量。 (gdb) r 9 Starting program: /home/lwy/workspace/gdbtest/main 9 Breakpoint 2, sum (value=9) at sum.c:3 3 int i = 0; (gdb) bt #0 sum (value=9) at sum.c:3 #1 0x0000555555555204 in main (argc=2, argv=0x7fffffffe048) at main.c:24 (gdb) bt full #0 sum (value=9) at sum.c:3 result = 0 i = 32767 #1 0x0000555555555204 in main (argc=2, argv=0x7fffffffe048) at main.c:24 io = 0x5555555592a0 命令格式如下： bt bt full：不仅显示backtrace，还显示局部变量 bt N：显示开头N个栈帧 bt full N ","date":"2021-04-07","objectID":"/gdb/:1:3","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"显示变量* print 变量名可以显示变量内容。 ptype 变量名 可以打印变量类型 如果需要一行监控多个变量，可以通过p {var1, var2, var3}。 如果要跟踪自动显示，可以使用display {var1, var2, var3} 取消跟踪用 undisplay 编号 查看文件代码：list/l [文件名:][行号/函数名] 设置显示的行数：show list/listsize , set list/listsize 行数 ","date":"2021-04-07","objectID":"/gdb/:1:4","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"显示寄存器* info reg可以显示寄存器内容。 (gdb) i r rax 0x9 9 rbx 0x555555555270 93824992236144 rcx 0x5555555592b0 93824992252592 rdx 0x9 9 rsi 0x0 0 rdi 0x9 9 rbp 0x7fffffffdf20 0x7fffffffdf20 rsp 0x7fffffffdf20 0x7fffffffdf20 r8 0x5555555592a0 93824992252576 r9 0x7ffff7dd1070 140737351848048 r10 0x7ffff7fb9be0 140737353849824 r11 0x7ffff7fb9be0 140737353849824 r12 0x5555555550a0 93824992235680 r13 0x7fffffffe040 140737488347200 r14 0x0 0 r15 0x0 0 rip 0x55555555524b 0x55555555524b \u003csum+25\u003e eflags 0x216 [ PF AF IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 gs 0x0 0 在寄存器名之前加$可以显示寄存器内容， p $寄存器：显示寄存器内容 p/x $寄存器：十六进制显示寄存器内容。 (gdb) p $ss $2 = 43 (gdb) p/x $pc $3 = 0x55555555524b 用x命令可以显示内容内容，x/格式 地址。 x $pc：显示程序指针内容 x/i $pc：显示程序指针汇编。 x/10i $pc：显示程序指针之后10条指令。 x/128wx 0xfc207000：从0xfc20700开始以16进制打印128个word。 (gdb) x $pc 0x55555555524b \u003csum+25\u003e: 0x00fc45c7 (gdb) x/i $pc =\u003e 0x55555555524b \u003csum+25\u003e: movl $0x0,-0x4(%rbp) (gdb) x/10i $pc =\u003e 0x55555555524b \u003csum+25\u003e: movl $0x0,-0x4(%rbp) 0x555555555252 \u003csum+32\u003e: jmp 0x555555555261 \u003csum+47\u003e 0x555555555254 \u003csum+34\u003e: mov -0x4(%rbp),%eax 0x555555555257 \u003csum+37\u003e: add $0x1,%eax 0x55555555525a \u003csum+40\u003e: add %eax,-0x8(%rbp) 0x55555555525d \u003csum+43\u003e: addl $0x1,-0x4(%rbp) 0x555555555261 \u003csum+47\u003e: mov -0x4(%rbp),%eax 0x555555555264 \u003csum+50\u003e: cmp -0x14(%rbp),%eax 0x555555555267 \u003csum+53\u003e: jl 0x555555555254 \u003csum+34\u003e 0x555555555269 \u003csum+55\u003e: mov -0x8(%rbp),%eax 还可以通过disassemble指令来反汇编。 disassemble disassemble 程序计数器 ：反汇编pc所在函数的整个函数。 disassemble addr-0x40,addr+0x40：反汇编addr前后0x40大小。 ","date":"2021-04-07","objectID":"/gdb/:1:5","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"单步执行* 单步执行有两个命令next和step，缩写为n和s，两者的区别是next遇到函数不会进入函数内部，step会执行到函数内部。 finish （跳出函数体） 如果需要逐条汇编指令执行，可以分别使用nexti和stepi。 ","date":"2021-04-07","objectID":"/gdb/:1:6","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"继续执行*  调试时，使用continue命令(缩写：c)继续执行程序。程序遇到断电后再次暂停执行；如果没有断点，就会一直执行到结束。 continue：继续执行 continue 次数：继续执行一定次数。 ","date":"2021-04-07","objectID":"/gdb/:1:7","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"监视点* 要想找到变量在何处被改变，可以使用watch命令设置监视点watchpoint。 watch \u003c表达式\u003e：表达式发生变化时暂停运行 awatch \u003c表达式\u003e：表达式被访问、改变是暂停执行 rwatch \u003c表达式\u003e：表达式被访问时暂停执行 (gdb) watch i Hardware watchpoint 3: i (gdb) i b Num Type Disp Enb Address What 2 breakpoint keep y 0x0000555555555244 in sum at sum.c:3 stop only if value==9 breakpoint already hit 1 time 3 hw watchpoint keep y ","date":"2021-04-07","objectID":"/gdb/:1:8","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"改变变量的值* 通过set variable \u003c变量\u003e=\u003c表达式\u003e来修改变量的值。 简写set var 变量名=变量值 （循环中用的多） until (跳出循环) (gdb) b main Breakpoint 4 at 0x555555555189: file main.c, line 11. (gdb) r 9 Starting program: /home/lwy/workspace/gdbtest/main 9 Breakpoint 4, main (argc=21845, argv=0x0) at main.c:11 11 { (gdb) n 12 struct inout * io = (struct inout * ) malloc(sizeof(struct inout)); (gdb) n 13 if (NULL == io) { (gdb) n 18 if (argc != 2) { (gdb) n 23 io -\u003e value = *argv[1] - '0'; (gdb) n 24 io -\u003e result = sum(io -\u003e value); (gdb) print io-\u003evalue $4 = 9 (gdb) set variable io-\u003evalue=10 (gdb) n 25 printf(\"Your enter: %d, result:%d\\n\", io -\u003e value, io -\u003e result); (gdb) n Your enter: 10, result:55 26 return 0; set $r0=xxx：设置r0寄存器的值为xxx。 ","date":"2021-04-07","objectID":"/gdb/:1:9","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"生成内核转储文件* 通过generate-core-file生成core.xxxx转储文件。 然后gdb ./main ./core.xxxx查看恢复的现场。 (gdb) generate-core-file warning: target file /proc/14188/cmdline contained unexpected null characters Saved corefile core.14188 lwy@lwysLaptop:~/workspace/gdbtest$ gdb ./main ./core.14188 Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from ./main... [New LWP 14188] Core was generated by `/home/lwy/workspace/gdbtest/main 9'. Program terminated with signal SIGTRAP, Trace/breakpoint trap. #0 main (argc=2, argv=0x7fffffffe048) at main.c:26 26 return 0; 另一命令gcore可以从命令行直接生成内核转储文件。 gcore pidof 命令：无需停止正在执行的程序以获得转储文件。 ","date":"2021-04-07","objectID":"/gdb/:1:10","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"attach到进程* 如果程序已经运行，或者是调试陷入死循环而无法返回控制台进程，可以使用attach命令。 attach pid 通过ps aux可以查看进程的pid，然后使用bt查看栈帧。 以top为例操作步骤为： ps -aux查看进程pid，为16974. sudo gdb attach 16974，使用gdb 附着到top命令。 使用bt full查看，当前栈帧。此时使用print等查看信息。 还可以通过info proc查看进程信息。 ","date":"2021-04-07","objectID":"/gdb/:1:11","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"反复执行 continue、step、stepi、next、nexti都可以指定重复执行的次数。 ignore 断点编号 次数：可以忽略指定次数断点。 ","date":"2021-04-07","objectID":"/gdb/:1:12","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"dump内存到指定文件 在gdb调试中可能需要将一段内存导出到文件中，可以借助dump命令。 命令格式： dump binary memory FILE START STOP 比如dump binary memory ./dump.bin 0x0 0x008000000，将内存区间从0x0到0x00800000导出到dump.bin中。 ","date":"2021-04-07","objectID":"/gdb/:1:13","tags":["GDB","Compile"],"title":"GDB调试基础","uri":"/gdb/"},{"categories":["Tools"],"content":"静态库 库文件是计算机上的一类文件，可以简单的把库文件看成一种代码仓库，它提供给使用者一些可以直接拿来用的变量、函数或类。 库是特殊的一种程序，编写库的程序和编写一般的程序区别不大，只是库不能单独运行。 库文件有两种，静态库和动态库（共享库），区别是：静态库在程序的链接阶段被复制到了程序中；动态库在链接阶段没有被复制到程序中，而是程序在运行时由系统动态加载到内存中供程序调用。 库的好处：1.代码保密 2.方便部署和分发 ","date":"2021-04-04","objectID":"/make_lib/:1:0","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"静态库的使用 通过gcc的-L命令指定库的路径，通过-l命令指定库的名字，注意这里库的名字不加lib,例如库的文件名为libxxx.lib那么库名就是xxx。 ","date":"2021-04-04","objectID":"/make_lib/:1:1","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"动态库 程序启动之后，动态库会被动态加载到内存中，通过 ldd （list dynamic dependencies）命令检查动态库依赖关系 如何定位共享库文件呢？ 当系统加载可执行代码时候，能够知道其所依赖的库的名字，但是还需要知道绝对路径。此时就需要系统的动态载入器来获取该绝对路径。对于elf格式的可执行程序，是由ld-linux.so来完成的，它先后搜索elf文件的 DT_RPATH段 ——\u003e 环境变量LD_LIBRARY_PATH ——\u003e /etc/ld.so.cache文件列表 ——\u003e /lib/，/usr/lib 目录找到库文件后将其载入内存。 ","date":"2021-04-04","objectID":"/make_lib/:2:0","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"动态库的使用 程序在执行的时候是如何定位共享库文件的呢？ 当系统加载可执行代码时候，能够知道其所依赖的库的名字，但是还需要知道绝对路径。此时就需要系统动态载入器(dynamic linker/loader)。 对于elf格式的可执行程序，是由ld-linux.so*来完成的，它先后搜索elf文件的 DT_RPATH段—\u003e环境变量LD_LIBRARY_PATH—\u003e/etc/ld.so.cache文件列表—\u003e/lib/,/usr/lib 目录找到库文件后将其载入内存。 如何让系统能够找到它： 如果安装在/lib或者/usr/lib下，那么ld默认能够找到，无需其他操作。 如果安装在其他目录，需要将其添加到/etc/ld.so.cache文件中，步骤如下： 编辑/etc/ld.so.conf文件，加入库文件所在目录的路径 运行ldconfig ，该命令会重建/etc/ld.so.cache文件 ","date":"2021-04-04","objectID":"/make_lib/:2:1","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"静态库与动态库对比 静态库特点总结： 静态库对函数库的链接是放在编译时期完成的。 程序在运行时与函数库再无瓜葛，移植方便。 浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件 动态库特点总结： 动态库把对一些库函数的链接载入推迟到程序运行的时期。 可以实现进程之间的资源共享。（因此动态库也称为共享库） 将一些程序升级变得简单。 甚至可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）。 静态库对程序的更新、部署和发布页会带来麻烦。如果静态库liba.lib更新了，所以使用它的应用程序都需要重新编译、发布给用户（对于玩家来说，可能是一个很小的改动，却导致整个程序重新下载，全量更新）。 动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，规避了空间浪费问题。动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可，增量更新。 ","date":"2021-04-04","objectID":"/make_lib/:3:0","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"Makefile 一个工程中的源文件不计其数，其按类型、功能、模块分别放在若干个目录中，Makefile 文件定义了一系列的规则来指定哪些文件需要先编译，哪些文件需要后编 译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为 Makefile 文件就 像一个 Shell 脚本一样，也可以执行操作系统的命令。 Makefile 带来的好处就是“自动化编译” ，一旦写好，只需要一个 make 命令，整 个工程完全自动编译，极大的提高了软件开发的效率。make 是一个命令工具，是一个 解释 Makefile 文件中指令的命令工具，一般来说，大多数的 IDE 都有这个命令， 比如 Delphi 的 make，Visual C++ 的 nmake，Linux 下 GNU 的 make。 ","date":"2021-04-04","objectID":"/make_lib/:4:0","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"Makefile规则 一个 Makefile 文件中可以有一个或者多个规则 目标 ...: 依赖 ... 命令（Shell 命令） ... 目标：最终要生成的文件（伪目标除外） 依赖：生成目标所需要的文件或是目标 命令：通过执行命令对依赖操作生成目标（命令前必须 Tab 缩进） Makefile 中的其它规则一般都是为第一条规则服务的 ","date":"2021-04-04","objectID":"/make_lib/:4:1","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"依赖检查与更新检测 命令在执行之前，需要先检查规则中的依赖是否存在 ，如果存在，执行命令 ，如果不存在，向下检查其它的规则，检查有没有一个规则是用来生成这个依赖的， 如果找到了，则执行该规则中的命令 在执行规则中的命令时，会比较目标和依赖文件的时间 。如果依赖的时间比目标的时间晚，需要重新生成目标 ，如果依赖的时间比目标的时间早，目标不需要更新，对应规则中的命令不需要被执行 ","date":"2021-04-04","objectID":"/make_lib/:4:2","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"变量 自定义变量 变量名=变量值 var=hello 预定义变量 AR : 归档维护程序的名称，默认值为 ar CC : C 编译器的名称，默认值为 cc CXX : C++ 编译器的名称，默认值为 g++ @ : 目标的完整名称 \u003c : 第一个依赖文件的名称 ^ : 所有的依赖文件 特殊命令 $(wildcard PATTERN...) 功能：获取指定目录下指定类型的文件列表 参数：PATTERN 指的是某个或多个目录下的对应的某种类型的文件，如果有多个目录，一般使用空格间隔 返回：得到的若干个文件的文件列表，文件名之间使用空格间隔 示例： $(wildcard *.c ./sub/*.c) 返回值格式: a.c b.c c.c d.c e.c f.c $(patsubst ,,) 功能：查找中的单词(单词以“空格”、“Tab”或“回车”“换行”分隔)是否符合模式，如果匹配的话，则以替换。 可以包括通配符%，表示任意长度的字串。如果 中也包含%，那么，中的这个%将是中的那个% 所代表的字串。(可以用\\来转义，以\\%来表示真实含义的%字符) 返回：函数返回被替换过后的字符串 示例：$(patsubst %.c, %.o, x.c bar.c) 返回值格式: x.o bar.o ","date":"2021-04-04","objectID":"/make_lib/:4:3","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Tools"],"content":"简单示例 #定义变量 src=sub.o add.o mult.o div.o main.o target=app $(target):$(src) $(CC) $(src) -o $(target) %.o:%.c $(CC) -c $\u003c -o $@ ","date":"2021-04-04","objectID":"/make_lib/:4:4","tags":["Unix","Makefile"],"title":"Makefile与库的制作","uri":"/make_lib/"},{"categories":["Operating System"],"content":"POSIX简介 ","date":"2021-03-29","objectID":"/posix/:1:0","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"1. 概念 POSIX：可移植操作系统接口（Portable Operating System Interface of UNIX，缩写为 POSIX ） ","date":"2021-03-29","objectID":"/posix/:1:1","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"2.发布者-IEEE 发布者为电气与电子工程师协会（Institute of Electrical and Electronics Engineers），简称IEEE。 IEEE，总部位于美国纽约，是一个国际性的电子技术与信息科学工程师的协会，也是目前全球最大的非营利性专业技术学会。IEEE致力于电气、电子、计算机工程和与科学有关的领域的开发和研究，在太空、计算机、电信、生物医学、电力及消费性电子产品等领域已制定了1300多个行业标准，现已发展成为具有较大影响力的国际学术组织 POSIX是IEEE为要在各种UNIX操作系统上运行的软件而定义的一系列API标准的总称，其正式称呼为IEEE 1003，而国际标准名称为ISO/IEC 9945。 POSIX.1 已经被国际标准化组织（International Standards Organization，ISO）所接受，被命名为 ISO/IEC 9945-1:1990 标准。 ","date":"2021-03-29","objectID":"/posix/:1:2","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"3.POSIX标准相关文件 Single UNIX Specification V3，IEEE Std 1003.1,2004 Edition 标准线上地址： The UNIX System 注册后可以在线阅读或者下载。 IEEE和Open Group 的POSIX认证： POSIX Certified by IEEE and The Open Group 相关页面： IEEE Std 1003.1, 2004 Edition ","date":"2021-03-29","objectID":"/posix/:1:3","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"POSIX历史 ","date":"2021-03-29","objectID":"/posix/:2:0","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"1.起源 POSIX是Unix的标准。 1974年，贝尔实验室正式对外发布Unix。因为涉及到反垄断等各种原因，加上早期的Unix不够完善，于是贝尔实验室以慷慨的条件向学校提供源代码，所以Unix在大专院校里获得了很多支持并得以持续发展。 于是出现了好些独立开发的与Unix基本兼容但又不完全兼容的OS，通称Unix-like OS。 包括： 美国加州大学伯克利分校的Unix4.xBSD(Berkeley Software Distribution)。 贝尔实验室发布的自己的版本，称为System V Unix。 其他厂商的版本，比如Sun Microsystems的Solaris系统,则是从这些原始的BSD和System V版本中衍生而来。 20世纪80年代中期，Unix厂商试图通过加入新的、往往不兼容的特性来使它们的程序与众不同。 局面非常混乱，麻烦也就随之而来了。 为了提高兼容性和应用程序的可移植性，阻止这种趋势， IEEE(电气和电子工程师协会)开始努力标准化Unix的开发，后来由 Richard Stallman命名为“Posix”。 这套标准涵盖了很多方面，比如Unix系统调用的C语言接口、shell程序和工具、线程及网络编程。 ","date":"2021-03-29","objectID":"/posix/:2:1","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"2.标准覆盖 市面上绝大多数操作系统厂家都支持该标准，首先就是大名鼎鼎的Unix和Linux了，除此之外还有苹果的操作系统也是Unix-based的。有了这个规范，你就可以调用通用的API了，Linux提供的POSIX系统调用在Unix上也能执行，因此学习Linux的底层接口最好就是理解POSIX标准。Windows从WinNT开始就有兼容POSIX的考虑。这是因为当年在要求严格的领域，Unix地位比Windows高。为了把Unix用户拉到Windows阵营，被迫支持POSIX。 现在Win10对 Linux/POSIX 支持好，则是因为Linux已经统治了廉价服务器市场。为了提高Windows的竞争力搞的。所以一切都是以市场为主导。 ","date":"2021-03-29","objectID":"/posix/:2:2","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"3.支持POSIX-Linux成功的最重要一个因素 Linux之所以能够成功，有很多因素，但是支持POSIX标准无疑是它能够快速发展的最重要的一个因素。 POSIX 标准的制定最后投票敲定阶段大概是 1991~1993 年间，而此时正是Linux 刚刚起步的时候，这个 UNIX 标准为 Linux 提供了极为重要的信息，使得 Linux 能够在标准的指导下进行开发，并能够与绝大多数 UNIX 操作系统兼容。 在最初的 Linux 内核源码（0.01版、0.11版）中就已经为 Linux 系统与 POSIX 标准的兼容做好了准备工作。 在 Linux 0.01 版内核 /include/unistd.h 文件中就已经定义了几个有关 POSIX 标准要求的符号常数，而且 Linus 在注释中已写道：“OK，这也许是个玩笑，但我正在着手研究它呢”。 正是由于Linux支持POSIX标准，无数可以在unix上运行的程序都陆续的移植到Linux上，而此时unix因为版权问题，官司打的不可开交，使得Linux后来者居上。 而Linus也在《知识为了好玩》中讲述了POSIX的重要性： POSIX标准是一个可以适用于数以百计的UNIX系统调用中的任意一个的一套冗长规则， 计算机要执行任务（从读、 写、 开机和关机开始） 就需要这个标准。 POSIX则是指一个UNIX的标准体系， 或一个由来自不同公司的代表所组成的一个组织， 希望按照一个共同的标准进行运作。 对于程序员开发的在该操作系统下的新应用软件或开发应用软件的新版本而言， 标准是极其重要的。 从POSIX这样的系统调用（system call） ， 尤其是重要的调用（call） 中， 我可以获得一个操作系统应该具有哪些功能的一个单子； 然后我就可以通过自己的方式在自己的系统中实现每一个功能。 通过编写出这些标准， 我的系统软件的源代码将可以被别人使用， 以开发新的应用软件。 当时我并不知道我本可以直接从POSIX公司买到这些规则的软盘， 但这无所谓。 哪怕我能买得起， 什么东西运到芬兰， 往往会需要很长的时间。 我不愿等上那么久， 因此我四处搜求一个能从FTP地址上直接下载的版本。 没有人给我提供能找到POSI标准的来源。 于是我开始了计划B。 我从学校找到运行sun器(sun server)的sun微系统版的UNIX手册。 该手册中有一个完全可以凑合使用的系统呼叫的基本版本。 从用户手册中能看出系统呼叫的主要功能， 以及为完成这些功能所需要完成的步骤。 但是， 从中看不出具体的方法， 而只是标明了最终的结果。 于是我便着手从安德鲁·塔南鲍姆的书中和别的材料中收集一些系统呼叫。 最终有人给我寄来了那几卷厚厚的POSIX标准。 ","date":"2021-03-29","objectID":"/posix/:2:3","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"可移植性 聊到POSIX，那我们就不得不说说到底什么是可移植性，在讲可移植性之前，我们先来了解库函数和系统调用的区别。 Linux下对文件操作有两种方式：系统调用（system call）和库函数调用（Library functions）。 ","date":"2021-03-29","objectID":"/posix/:3:0","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"1.系统调用 系统调用是通向操作系统本身的接口，是面向底层硬件的。通过系统调用，可以使得用户态运行的进程与硬件设备(如CPU、磁盘、打印机等)进行交互，是操作系统留给应用程序的一个接口。 ","date":"2021-03-29","objectID":"/posix/:3:1","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"2.库函数 库函数（Library function）是把函数放到库里，供别人使用的一种方式。 方法是把一些常用到的函数编完放到一个文件里，供不同的人进行调用。一般放在.lib文件中。 库函数调用则是面向应用开发的，库函数可分为两类， 一类是C语言标准规定的库函数， 一类是编译器特定的库函数。 (由于版权原因，库函数的源代码一般是不可见的，但在头文件中你可以看到它对外的接口)。 glibc 是 Linux 下使用的开源的标准 C 库，它是 GNU 发布的 libc 库，即运行时库。这些基本函数都是被标准化了的，而且这些函数通常都是用汇编直接实现的。 glibc 为程序员提供丰富的 API（Application Programming Interface），这些API都是遵循POSIX标准的，API的函数名，返回值，参数类型等都必须按照POSIX标准来定义。 POSIX兼容也就指定这些接口函数兼容，但是并不管API具体如何实现。 ","date":"2021-03-29","objectID":"/posix/:3:2","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"3.库函数API和系统调用的区别 如上图所示： (1) 库函数是语言或应用程序的一部分，而系统调用是内核提供给应用程序的接口，属于系统的一部分 (2) 库函数在用户地址空间执行，系统调用是在内核地址空间执行，库函数运行时间属于用户时间，系统调用属于系统时间，库函数开销较小，系统调用开销较大 (3) 系统调用依赖于平台，库函数并不依赖 系统调用是为了方便使用操作系统的接口，而库函数则是为了人们编程的方便。 库函数调用与系统无关，不同的系统，调用库函数，库函数会调用不同的底层函数实现，因此可移植性好。 ","date":"2021-03-29","objectID":"/posix/:3:3","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"4.程序的可移植性及其本质 程序在不同的机器上会生成不同的目标代码，那么目标代码和启动代码是怎么生成的呢？ 答案是编译器。 编程语言编写的程序首先要被编译器编译成目标代码（0、1代码），然后在目标代码的前面插入启动代码，最终生成了一个完整的程序。 要注意的是，程序中为访问特定设备（如显示器）或者操作系统（如windows xp 的API)的特殊功能而专门编写的部分通常是不能移植的。 综上所述，一个编程语言的可移植性取决于 不同平台编译器的数量 对特殊硬件或操作系统的依赖性 移植是基于操作系统的。但是这个时候，我们需要注意一点：基于各种操作系统平台不同，应用程序在二级制级别是不能直接移植的。 我们只能在代码层去思考可移植问题，在API层面上由于各个操作系统的命名规范、系统调用等自身原因，在API层面上实现可移植也是不大可能的。 在各个平台下，我们默认C标准库中的函数都是一样的，这样基本可以实现可移植。但是对于C库本身而言，在各种操作系统平台下其内部实现是完全不同的，也就是说C库封装了操作系统API在其内部的实现细节。 因此，C语言提供了我们在代码级的可移植性，即这种可移植是通过C语言这个中间层来完成的。 例如在我们的代码中下功夫。以下代码可以帮助我们实现各平台之间的可移植： #ifdef _WINDOWS_ CreateThread(); //windows下线程的创建 #else Pthread_create(); //Linux下线程的创建 #endif 对于头文件，也使用同样的预编译宏来实现。如： #ifndef _WINDOWS_ #include \u003cwindows.h\u003e#else #include \u003cthread.h\u003e#endif 这样就可以实现代码的可移植了。在编译的时候只要通过#define就可以选择在那个平台下完成程序的编译。 综上所述，我们都是将C，C++等各种语言当作中间层，以实现其一定程度上的可移植。如今，语言的跨平台的程序都是以这样的方式实现的。但是在不同的平台下，仍需要重新编译。 ","date":"2021-03-29","objectID":"/posix/:3:4","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"5.系统开销 使用系统调用会影响系统的性能，在执行调用时的从用户态切换到内核态，再返回用户态会有系统开销。 为了减少开销，因此需要减少系统调用的次数，并且让每次系统调用尽可能的完成多的任务。 硬件也会限制对底层系统调用一次所能写的数据块的大小。 为了给设备和文件提供更高层的接口，Linux系统提供了一系列的标准函数库。 使用标准库函数，可以高效的写任意长度的数据块，库函数在数据满足数据块长度要求时安排执行底层系统调用。 一般地，操作系统为了考虑实现的难度和管理的方便，它只提供一少部分的系统调用，这些系统调用一般都是由C和汇编混合编写实现的，其接口用C来定义，而具体的实现则是汇编，这样的好处就是执行效率高，而且，极大的方便了上层调用。 随着系统提供的这些库函数把系统调用进行封装或者组合，可以实现更多的功能，这样的库函数能够实现一些对内核来说比较复杂的操作。 比如，read()函数根据参数，直接就能读文件，而背后隐藏的比如文件在硬盘的哪个磁道，哪个扇区，加载到内存的哪个位置等等这些操作，程序员是不必关心的，这些操作里面自然也包含了系统调用。 而对于第三方的库，它其实和系统库一样，只是它直接利用系统调用的可能性要小一些，而是利用系统提供的API接口来实现功能(API的接口是开放的)。 ","date":"2021-03-29","objectID":"/posix/:3:5","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["Operating System"],"content":"例子 如下图是Linux系统调用的大概流程。 当应用程序调用printf()函数时，printf函数会调用C库中的printf，继而调用C库中的write，C库最后调用内核的write()。 而另一些则不会使用系统调用，比如strlen, strcat, memcpy等。 printf函数执行过程中，程序运行状态切换如下： 用户态–\u003e系统调用–\u003e内核态–\u003e返回用户态 printf函数、glibc库和系统调用在系统中关系图如下 实例代码如下： #include \u003cstdio.h\u003e int main(int argc, char **argv) { printf(\"hello world\"); return 0; } 编译执行 lwy@lwysLaptop:~/workspace$ gcc test.c -o test \u0026\u0026 strace ./test 运行程序前加上strace，可以追踪到函数库调用过程 如执行结果可知： 我们的程序虽然只有一个printf函数，但是在执行过程中，我们前后调用了execve、access、open、fstat、mmap、brk、write等系统调用。 其中write系统调用会把字符串：hello world通过设备文件1，发送到驱动，该设备节点对应终端stdout。 ","date":"2021-03-29","objectID":"/posix/:4:0","tags":["Unix","GNU"],"title":"POSIX是什么","uri":"/posix/"},{"categories":["C/C++"],"content":"IFNDEF ifndef的含义是If not define, 其搭配使用如下 // xxx.h #ifndef __INCxxx.h #define __INCxxx.h #ifndef __cpluscplus extern \"C\" { #endif /*...*/ #ifndef } #endif #endif ","date":"2021-03-19","objectID":"/ifndef/:1:0","tags":null,"title":"关于C语言中的IFNDEF宏","uri":"/ifndef/"},{"categories":["C/C++"],"content":"1.多次包含的情况 include xxx 就是将xxx的内容原地展开 假设有： a.h， 内容是 A b.h， 内容是： #include \"a.h\" B c.h， 内容是： #include \"a.h\" C 如果有一个文件x.c， 内容是： #include \"b.h\" #include \"c.h\" X b.h和c.h的内容就会被插入到X之前， 也就是这个样子： A B A C X A的内容就出现了2次。 在更复杂的环境中， A的内容还可能出现多次。 ","date":"2021-03-19","objectID":"/ifndef/:1:1","tags":null,"title":"关于C语言中的IFNDEF宏","uri":"/ifndef/"},{"categories":["C/C++"],"content":"2.多次出现是有问题的 一般来说， 重复声明没什么问题。 所以， 如果A.h中止包含一些声明， 那重复了也没什么关系。 比如： int f(int); int f(int); int f(int); extern int i; extern int i; extern int i; struct x; struct x; struct x; 重复写N次也没关系。 但头文件中会出现一类\"定义\"， 在同一翻译单元中是不能重复的。 比如： struct x { ... }; struct x { ... }; // 重复定义 #define M ... #define M ... // 重复定义 ","date":"2021-03-19","objectID":"/ifndef/:1:2","tags":null,"title":"关于C语言中的IFNDEF宏","uri":"/ifndef/"},{"categories":["C/C++"],"content":"3.头文件保护符 有时候必须将这些定义放在头文件中， 所以就要用头文件保护符。 另外还有一类\"定义\"， 会产生外部符号。 这类\"定义\"在一个链接过程中只能有唯一一份。 是不可以加入到头文件中的。 这种定义依然有例外…… 就是inline、模板和匿名名字空间， 就不扯远了…… 假设A的内容是： #ifndef A_H #define A_H AA #endif 如果A被展开多次，例如上面的X， 就会变成这个样子 // A_H是a.h的保护符， 必须是一个不冲突的名字。 那么，这里就不会有A_H的定义 // 然后紧接这下一行中的条件编译就会选中#ifndef 和#endif之间的部分， // 也就是#define A_H 和AA #ifndef A_H #define A_H AA #endif B // 在a.h被第一次包含后， A_H就获得定义 // 所以下一行的条件编译部分就被取消， AA就不会重复出现多次 #ifndef A_H #define A_H AA #endif C X 最终交给编译器看到的代码就是： AA B C X 只要A_H是唯一的， AA就不会重复出现。 就解决了这个问题， 一般情况就是这么用的， 是为惯例。 ","date":"2021-03-19","objectID":"/ifndef/:1:3","tags":null,"title":"关于C语言中的IFNDEF宏","uri":"/ifndef/"},{"categories":["C/C++"],"content":"4.外部头文件保护符 上面的用法是\"内部头文件保护符\"。 a.h的保护符是使用在a.h里。 另外一种用法是\"外部头文件保护符\"， 如： ------ a.h ------ AA ------ b.h ------ #ifndef A_H #define A_H #include \"a.h\" #endif B ------ c.h ------ #ifndef A_H #define A_H #include \"a.h\" #endif C 当X同时包含b.h和c.h时， 最终效果和内部头文件保护符差不多。 两者对比， 外部的优势是可以减少打开a.h的次数。 而内部保护符可以降低a.h和b.h, c.h之间的耦合。 ","date":"2021-03-19","objectID":"/ifndef/:1:4","tags":null,"title":"关于C语言中的IFNDEF宏","uri":"/ifndef/"},{"categories":["C/C++"],"content":"5.定义保护符 马上就要到主题了…… 将头文件保护符的用法扩展一下， 就变成了定义保护符（这个名字是我捏造的）。 保护的不是某个\"头文件\" 而是某个\"定义\"， 如： ------ a.h ------ #ifndef A_X #define A_X struct x { ... }; #endif #ifndef A_M #define A_M #define M ... #endif ... b.h和c.h直接包含a.h， 最终效果也是一样。 ","date":"2021-03-19","objectID":"/ifndef/:1:5","tags":null,"title":"关于C语言中的IFNDEF宏","uri":"/ifndef/"},{"categories":["C/C++"],"content":"6.重复的定义保护符 到主题了…… 同样是一个捏造的词。 假设： b.h包含a.h是为了获得struct x的定义。 而c.h包含a.h是为了获得宏M的定义。 除了上面作法， 还有另一种做法： a.h和上面差不多 #ifndef X #define X struct x { ... }; #endif #ifndef M #define M ... #endif 而b.h和c.h并不包含a.h， 而是直接将需要的定义写在b.h和c.h中 ------ b.h ------ #ifndef X #define X struct x { ... }; #endif B ------ c.h ------ #ifndef M #define M ... #endif C 这样做其实耦合比外部头文件保护符还要高， 所以一般是不会采用的。 但C的标准头文件必须这样做。 因为C89有一个要求， 具体我不记得了。 要么是要求标准头文件不能包含其他标准头文件。 要么是要求标准头文件不能包含任何其他文件。 （C++和C99取消了这个要求） stdio.h是C89的标准头文件。 例如， 它需要定义一个size_t， 作为一些函数的参数类型。 而另外有一些标准头文件也会有size_t。 所以这些头文件中的size_t都是这样提供的： #ifndef _SIZE_T_DEFINED #define _SIZE_T_DEFINED typedef unsigned xxx size_t; #endif 或者也可能将若干定义分组， 共用一个保护符。 ","date":"2021-03-19","objectID":"/ifndef/:1:6","tags":null,"title":"关于C语言中的IFNDEF宏","uri":"/ifndef/"}]